{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os, sys, warnings\n",
    "import ipdb\n",
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torchnet as tnt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# add paths for all sub-folders\n",
    "paths = [root for root, dirs, files in os.walk('.')]\n",
    "for item in paths:\n",
    "    sys.path.append(item)\n",
    "\n",
    "from ipynb.fs.full.config import Config\n",
    "from ipynb.fs.full.monitor import Visualizer\n",
    "from ipynb.fs.full.network import MobileNetV2\n",
    "from ipynb.fs.full.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for debugging only\n",
    "%pdb off\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# imageNet mean and std\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# choose GPU if available\n",
    "device = t.device('cuda' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "# define model\n",
    "opt = Config()\n",
    "model = MobileNetV2().to(device)\n",
    "\n",
    "# load pre-trained model if necessary\n",
    "if opt.save_root:\n",
    "    model.load(opt.save_root)\n",
    "\n",
    "# dataloader for training\n",
    "train_dir = os.path.join(opt.data_root, 'train')\n",
    "train_dataset = tv.datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    tv.transforms.Compose([\n",
    "        tv.transforms.RandomResizedCrop(opt.img_size, scale=(0.2, 1.0)),\n",
    "        tv.transforms.RandomHorizontalFlip(),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ]))\n",
    "train_loader = t.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.num_workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "# dataloader for validation\n",
    "val_dir = os.path.join(opt.data_root, 'val')\n",
    "val_dataset = tv.datasets.ImageFolder(\n",
    "    val_dir,\n",
    "    tv.transforms.Compose([\n",
    "        tv.transforms.Resize(int(opt.img_size / 0.875)),\n",
    "        tv.transforms.CenterCrop(opt.img_size),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "    ]))\n",
    "val_loader = t.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.num_workers,\n",
    "    pin_memory=True)\n",
    "\n",
    "# optimizer\n",
    "criterion = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=opt.lr,\n",
    "    momentum=opt.momentum,\n",
    "    weight_decay=opt.weight_decay)\n",
    "scheduler = t.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=opt.upd_freq, gamma=opt.lr_decay)\n",
    "\n",
    "# visualizer\n",
    "vis = Visualizer(port=8866)\n",
    "loss_meter = tnt.meter.AverageValueMeter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     28
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for (img_batch, gnd_batch) in val_loader:\n",
    "        # inference\n",
    "        with t.no_grad():\n",
    "            img_batch = img_batch.to(device)\n",
    "            gnd_batch = gnd_batch.to(device)\n",
    "            pred_batch = model(img_batch)\n",
    "\n",
    "        # match results\n",
    "        _, index_batch = t.topk(pred_batch.data, 5, dim=1)\n",
    "        index_batch = index_batch.t()\n",
    "        gnd_batch = gnd_batch - 1\n",
    "        total += gnd_batch.size(0)\n",
    "        correct += index_batch.eq(\n",
    "            gnd_batch.view(1, -1).expand_as(index_batch)).sum()\n",
    "\n",
    "    # training mode\n",
    "    model.train(mode=True)\n",
    "\n",
    "    return float(correct) / float(total) * 100.0\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(opt.max_epoch), desc='epoch', total=opt.max_epoch):\n",
    "    # reset meter and update learning rate\n",
    "    loss_meter.reset()\n",
    "    scheduler.step()\n",
    "\n",
    "    for index, (img_batch, gnd_batch) in enumerate(train_loader):\n",
    "        # reset gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # inference\n",
    "        img_batch = img_batch.to(device)\n",
    "        gnd_batch = gnd_batch.to(device)\n",
    "        pred_batch = model(img_batch)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(pred_batch, gnd_batch)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # add to loss meter for logging\n",
    "        loss_meter.add(loss.item())\n",
    "        if (index + 1) % opt.plot_freq == 0:\n",
    "            vis.plot('loss', loss_meter.value()[0])\n",
    "            vis.log('epoch: {epoch}, loss: {loss:.5f}'.format(\n",
    "                epoch=epoch, loss=loss_meter.value()[0]))\n",
    "\n",
    "    # save model\n",
    "    model.save()\n",
    "\n",
    "    # validation\n",
    "    accuracy = validate()\n",
    "    vis.log('lr: {lr:.5f}, acc@5: {top5:.3f}'.format(\n",
    "        lr=opt.lr * opt.lr_decay**(epoch // opt.upd_freq), top5=accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
